{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jgamero-ibrobotics/trabajo-pic/blob/Jesus/TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import thop\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para que se importe de tu drive el zip del dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descomprimir el zip\n",
    "zip_path = 'drive/MyDrive/archive.zip'\n",
    "extract_folder = 'data'\n",
    "\n",
    "# Create the extraction folder if it doesn't exist\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# Extract the contents of the ZIP file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar datasets\n",
    "Descarga  el dataset, le da el formato de resnet y crea los conjuntos de train, test y valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/AugmentedAlzheimerDataset/\"\n",
    "MINIBATCH_SIZE = 32\n",
    "\n",
    "train_transforms = T.Compose([T.Resize((224,224)),\n",
    "                                    T.RandomRotation(60),\n",
    "                                       T.RandomHorizontalFlip(),\n",
    "                                       T.ToTensor(),\n",
    "                                       T.Normalize([0.485, 0.456, 0.406],\n",
    "                                                   [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Descargamos los datos de datapath\n",
    "midataset = datasets.ImageFolder(DATA_PATH,\n",
    "                                 transform=train_transforms)\n",
    "\n",
    "train_size = int(0.9 * len(midataset))\n",
    "val_size = int(0.04 * len(midataset))\n",
    "test_size = len(midataset) - train_size - val_size\n",
    "train_midataset, test_midataset, val_midataset = torch.utils.data.random_split(midataset, [train_size, test_size, val_size])\n",
    "\n",
    "train_loader  = torch.utils.data.DataLoader(train_midataset,MINIBATCH_SIZE,shuffle=True)\n",
    "val_loader  = torch.utils.data.DataLoader(val_midataset,MINIBATCH_SIZE,shuffle=False)\n",
    "test_loader  = torch.utils.data.DataLoader(test_midataset,MINIBATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(val_loader):\n",
    "    print(i, x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images(dataset_path):\n",
    "    classes = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "    num_images = 4\n",
    "    \n",
    "    # Plot images for each class\n",
    "    for class_name in classes:\n",
    "        class_folder = os.path.join(dataset_path, class_name)\n",
    "        image_files = os.listdir(class_folder)\n",
    "        random_images = random.sample(image_files, num_images)\n",
    "        \n",
    "        plt.figure(figsize=(12, 3))\n",
    "        plt.suptitle(f'Random images from class: {class_name}', fontsize=14)\n",
    "        \n",
    "        for i, image_file in enumerate(random_images):\n",
    "            image_path = os.path.join(class_folder, image_file)\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            plt.subplot(1, num_images, i + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Call the function with the path to your dataset folder\n",
    "plot_random_images('data/AugmentedAlzheimerDataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular Accuracy y Perdida\n",
    "Función para probar el modelo sobre un conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader): # funcion para calcular la precision del modelo\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    epoch_loss = 0.0\n",
    "    model.eval() # ponemos el modelo en modo evaluacion\n",
    "    model = model.to(device=device) # movemos el modelo al device (cpu o gpu)\n",
    "    with torch.no_grad(): # deshabilitamos el calculo del gradiente (no necesita actualizar pesos)\n",
    "\n",
    "        # xi: datos de entrada, yi: etiquetas\n",
    "        for (xi, yi) in loader: # iteramos sobre los minibatches del loader de validacion o test \n",
    "            xi = xi.to(device=device, dtype = torch.float32) # movemos los datos al device (cpu o gpu) \n",
    "            yi = yi.to(device=device, dtype = torch.long) # movemos los datos al device (cpu o gpu)\n",
    "            scores = model(xi) # mb_size, 10. corre el modelo sobre los datos de entrada\n",
    "            loss =  F.cross_entropy(input=scores, target=yi)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            _, pred = scores.max(dim=1) #pred shape (mb_size). obtenemos la clase con mayor score (prediccion)   \n",
    "            # comparamos las predicciones con las etiquetas y sumamos el numero de predicciones correctas\n",
    "            num_correct += (pred == yi).sum() # pred shape (mb_size), yi shape (mb_size, 1).\n",
    "            # sumamos 1 por cada prediccion correcta\n",
    "            num_total += pred.size(0)\n",
    "\n",
    "\n",
    "        loss_ = epoch_loss / len(loader)\n",
    "        accuracy = float(num_correct)/num_total   \n",
    "\n",
    "        return loss_, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet121 = models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploremos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, w in enumerate(model_resnet121.parameters()):\n",
    "    print(i, w.shape, w.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_resnet121 = model_resnet121.to(device=device)\n",
    "summary(model_resnet121, (3, 224, 224))\n",
    "flops, params = thop.profile(model_resnet121, verbose=False,\n",
    "                             inputs=(torch.randn(1, 3, 224, 224).to(device),))\n",
    "(flops, params) = thop.clever_format([flops, params])\n",
    "print(f'FLOPs: {flops}, params: {params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustar a nuestro modelo\n",
    "Eliminamos la ultima capa lineal dle modelo para añadir la nuestra con las 10 salidas que necesitamos segun las clases de nuestro dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponemos el resto de parametros de la red a false para que no se ajustan en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, parameter in enumerate(model_resnet121.parameters()):\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "for param in model_resnet121.features.denseblock4.parameters():#solo los de este bloque se ponen a True para que se modifiquen\n",
    "    param.requires_grad =True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, parameter in enumerate(model_resnet121.parameters()):\n",
    "    print(i, parameter.requires_grad) # los que son True se modifican, los que son False no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader, lr_scheduler):\n",
    "    \n",
    "    for (xi, yi) in loader:\n",
    "        model.train()\n",
    "        xi = xi.to(device=device, dtype=torch.float32) \n",
    "        yi = yi.to(device=device, dtype=torch.long)\n",
    "        scores = model(xi)\n",
    "        loss = F.cross_entropy(input= scores, target=yi)\n",
    "    \n",
    "        optimizer.zero_grad()           \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0015\n",
    "epochs = 10\n",
    "\n",
    "model_resnet121.classifier=torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.2,inplace=True),\n",
    "            torch.nn.Linear(1024,4),)   \n",
    "\n",
    "optimizer = torch.optim.Adam(model_resnet121.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_resnet121 = model_resnet121.to(device=device)\n",
    "summary(model_resnet121, (3, 224, 224))\n",
    "flops, params = thop.profile(model_resnet121, verbose=False,\n",
    "                             inputs=(torch.randn(1, 3, 224, 224).to(device),))\n",
    "(flops, params) = thop.clever_format([flops, params])\n",
    "print(f'FLOPs: {flops}, params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model_resnet121.to(device=device)\n",
    "best_acc = 0.0\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "lr_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(model1, optimizer, train_loader, lr_scheduler)\n",
    "    epoc_val_loss, epoc_val_accuracy = test(model1, val_loader)\n",
    "    epoc_train_loss, epoc_train_accuracy = test(model1, train_loader)\n",
    "\n",
    "    if best_acc <= epoc_train_accuracy:\n",
    "        best_acc = epoc_train_accuracy\n",
    "        best_model = copy.deepcopy(model1)\n",
    "\n",
    "    train_loss_history.append(epoc_train_loss)\n",
    "    train_acc_history.append(epoc_train_accuracy)   \n",
    "    val_loss_history.append(epoc_val_loss)\n",
    "    val_acc_history.append(epoc_val_accuracy) \n",
    "    lr_history.append(lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "    print(f'Epoch: {epoch} ACCURACY (validation): {epoc_val_accuracy:.4f}, ACCURACY (train): {epoc_train_accuracy:.4f},\\\n",
    "           LOSS (validation): {epoc_val_loss:.4f}, LOSS (train): {epoc_train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de la evolución de la pérdida y la precisión\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(train_loss_history, label='train')\n",
    "plt.plot(val_loss_history, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_acc_history, label='train')\n",
    "plt.plot(val_acc_history, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(lr_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a poner todos los parametros de la red a true, para realizar una segunda vuelta de entrenamiento y que asi conseguir que la red generalice mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, parameter in enumerate(best_model.parameters()):\n",
    "    parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_model.to(device=device)\n",
    "summary(best_model, (3, 224, 224))\n",
    "flops, params = thop.profile(best_model, verbose=False,\n",
    "                             inputs=(torch.randn(1, 3, 224, 224).to(device),))\n",
    "(flops, params) = thop.clever_format([flops, params])\n",
    "print(f'FLOPs: {flops}, params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_model.to(device=device)\n",
    "best_acc = 0.0\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "lr_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train(best_model, optimizer, train_loader, lr_scheduler)\n",
    "    epoc_val_loss, epoc_val_accuracy = test(best_model, val_loader)\n",
    "    epoc_train_loss, epoc_train_accuracy = test(best_model, train_loader)\n",
    "\n",
    "    if best_acc <= epoc_val_accuracy:\n",
    "        best_acc = epoc_val_accuracy\n",
    "        best_model_2 = copy.deepcopy(best_model)\n",
    "\n",
    "    train_loss_history.append(epoc_train_loss)\n",
    "    train_acc_history.append(epoc_train_accuracy)   \n",
    "    val_loss_history.append(epoc_val_loss)\n",
    "    val_acc_history.append(epoc_val_accuracy) \n",
    "    lr_history.append(lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "    print(f'Epoch: {epoch} ACCURACY (validation): {epoc_val_accuracy:.4f}, ACCURACY (train): {epoc_train_accuracy:.4f},\\\n",
    "           LOSS (validation): {epoc_val_loss:.4f}, LOSS (train): {epoc_train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = test(best_model_2, test_loader)\n",
    "print(f'ACCURACY (test): {test_acc:.4f}, LOSS (test): {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcticamos la inferencia sobre el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_2.eval()\n",
    "rnd_sample_idx = np.random.randint(len(test_loader))\n",
    "xi = test_loader.dataset[rnd_sample_idx][0]\n",
    "yi = test_loader.dataset[rnd_sample_idx][1]\n",
    "xi = xi.to(device=device, dtype = torch.float32) # movemos los datos al device (cpu o gpu) \n",
    "print(f'La imagen muestreada representa un: {classes[test_loader.dataset[rnd_sample_idx][1]]}')\n",
    "image = test_loader.dataset[rnd_sample_idx][0]\n",
    "image = (image - image.min()) / (image.max() -image.min() )\n",
    "\n",
    "scores = best_model_2(xi.unsqueeze(0))\n",
    "_, pred = scores.max(dim=1)\n",
    "print(f'La clase predicha es: {classes[pred]}')\n",
    "plot_figure(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
